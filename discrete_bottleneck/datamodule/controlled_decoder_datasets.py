from torch.utils.data import Dataset
from .abstract_controlled_decoder_dataset import AbstractControlledDecoderDataset
import numpy as np
from itertools import product
import random
from .utils.controlled_decoder_utils import dist_generators
from .utils.controlled_decoder_utils import extra_dist_generator

class ControlledDecoderDataset(AbstractControlledDecoderDataset):
    """
    A torch.utils.data.Dataset of numeric sequences generated by a decoder f
    from a specified discrete structure Z.
    f can have a combination of the following properties:
        - deterministic vs. stochastic
        - invertible vs. non-invertible
        - real number output vs. sequence outputs
    Z can be any of the following structures:
        - One discrete variable with 2 possible values (1 bit of information)
        - One discrete variable with n possible values
        - M discrete variables, each with n possible values (cross-product space)
        - Compositional, grammar-like
        
    Any dataset of this type should implement the following functions:
        * _decode(self, z)
            This function should take a sample z from the discrete structure Z defined in the __init__
            and decode it based on the decoding function specified in _decode()
        
        * _generate_data(self)
            Based on the type of discrete structure Z, it should generate either all deterministic
            samples, or as many stochastic samples as requested. 
    """

    def __init__(self, **kwargs):
        """
        Parameters
        ----------
        split : The split to load. Must be equal to 'train', 'val' or 'test'.
        seed : Random seed

        kwargs: properties of the decoder and latent's discrete structure.

        Returns
        -------
        An instance of the numeric sequence dataset that extends torch.utils.data.Dataset.
        """
        
        self.num_samples = kwargs['num_samples']
        self.decoder_parameters = kwargs['decoder_parameters']
        self.db_parameters = kwargs['discrete_bottleneck_parameters']
        
            
        super().__init__(**kwargs)
        
        
        
    def _generate_data(self):
        
        if self.use_mapping is False:
            self.mappings, self.Z = self._create_mappings()
        else:
            _, self.Z = self._create_mappings()

        discrete_samples = random.choices(self.Z, k = self.num_samples)
        decoded_samples = self._decode(discrete_samples)
        return list(enumerate(decoded_samples)), discrete_samples

    
    def _decode(self, discrete_samples):
        """
        Based on the decoder being stochastic or not, we should either just use
        the indexes in enumerate to get the deterministic sequences or decode 
        using lambda generator functions. 
        """
        
        if self.decoder_parameters['deterministic']:
            return [self.mappings[x[0]][1] for x in discrete_samples]
        else:
            return [[y() for y in self.mappings[x[0]][1]] for x in discrete_samples]

        
    def _create_mappings(self):
        
        Z_values = np.arange(self.db_parameters['num_possible_values'])
        # length of the sequence in discrete bottleneck
        db_len = self.db_parameters['sequence_length']
        # cartesian product of possible values of Z for db_len times.
        Z_product_list = db_len * [Z_values]
        Z_product = list(product(*Z_product_list))
        
        deterministic = self.decoder_parameters['deterministic']
        invertible = self.decoder_parameters['invertible']
        
        output_len = self.decoder_parameters['output_length']
        non_invertible_percentage = self.decoder_parameters['non_invertible_percentage']

        # This determines the equivalence class up to which the inverse of the decoder can learn
        # If non_invertible_count = int(len(Z_product)*non_invertible_percentage) then the degree
        # can be anywhere \in {2,..., non_invertible_count}-{non_invertible_count-1} because if
        # non_invertible_count-1 have the same value then the last element in non_invertible_count 
        # would become invertible because it has a unique assignment.

        non_invertibility_maximum_degree = self.decoder_parameters['non_invertibility_maximum_degree']
        dist_params = self.decoder_parameters['dist_params']


        if invertible: # should select as many different numbers as there are permutations

            # if the output is binary, then it should be checked whether there are as many 
            # permutations as invertibility requires
            # for now let's consider binary values for sequence outputs (hence the 2 on the rhs)
            assert len(Z_values) ** db_len <= 2 ** output_len

            # create all possible output sequences
            if deterministic:
                output_values = [0,1] # assuming they only possess binary values.
            else:
                dist_pos, dist_neg = dist_generators(dist_params)
                output_values = [dist_pos, dist_neg]
                
                # for the case of invertible decoder, if the following happens, we need more non-overlapping distributions (i.e. uniform)
                if len(Z_values) ** db_len > 2: 
                    for i in range(len(Z_values)-2):
                        temp_dist = lambda : np.random.uniform(dist_params['uniform']['positive_dist']['low']+i, dist_params['uniform']['positive_dist']['high']+i, 1)[0]
                        output_values.append(temp_dist)

            product_list = output_len * [output_values]
            output_cartesian_product = list(product(*product_list))

            # randomly choose len(Z_product) of output_cartesian_product to assign them to Z_products
            assignments = random.sample(output_cartesian_product, len(Z_product))

            # return the created mapping
            mapping, Z = list(enumerate(assignments)), list(enumerate(Z_product)) 

        else:

            # Take some percentage of all Z_products, and make sure for any element
            # in that subset there exists at least one other element with the same
            # output. Also remove the assignments used here from the set of possible
            # assignments so the rest of the discrete sequences remain invertible.

            # create all possible sequences
            if deterministic:
                output_values = [0,1] # assuming they only possess binary values.
            else:
                dist_pos, dist_neg = dist_generators(dist_params)
                output_values = [dist_pos, dist_neg]
                
                # for the case of non-invertible stochastic decoder, if the following happens, we need more distributions but they need
                # not be uniform, they can follow the original distribution with some predefined alteration.
                if len(Z_values) ** db_len > 2: 
                    for i in range(len(Z_values)-2):
                        temp_dist = extra_dist_generator(dist_params, i)
                        output_values.append(temp_dist)
                

            product_list = output_len * [output_values]
            output_cartesian_product = list(product(*product_list))

            # randomly choose non_invertible_percentage of Z_product to make it non-invertible
            non_invertible_count = int(np.floor(non_invertible_percentage * len(Z_product)))
            if non_invertible_count < 2:
                non_invertible_count = 2 # if it's less than 2, then non-invertibility doesn't make sense

            non_invertible_Z = random.sample(list(enumerate(Z_product)), non_invertible_count)
            invertible_Z = list(enumerate(Z_product))
            for z in non_invertible_Z:
                invertible_Z.remove(z)

            remaining_assignments = output_cartesian_product
            mapping = []

            # creating the mapping for non-invertible discrete latents

            # check possible_degrees != non_invertible_count-1
            # check maximum_degree be less than or equal to non_invertible_count
            if non_invertibility_maximum_degree > non_invertible_count:
                non_invertibility_maximum_degree = non_invertible_count

            possible_degrees = list(np.arange(2, non_invertibility_maximum_degree+1))
            if non_invertibility_maximum_degree-1 in possible_degrees:
                possible_degrees.remove(non_invertibility_maximum_degree-1)


            while len(non_invertible_Z) >= 2:

                if len(non_invertible_Z) == 2:

                    # pick an assignment from remaining_assignments
                    assignment = random.sample(remaining_assignments, 1)[0] # it returns a list with one elements, hence picking the [0] index
                    # remove the assignment from remaining_assignments

                    remaining_assignments.remove(assignment)

                    for z in non_invertible_Z:
                        mapping.append((z[0], assignment))

                    non_invertible_Z_temp = non_invertible_Z # to not loop over a list and edit it at the same time
                    for z in non_invertible_Z_temp:
                        # remove the z from the list of non_invertibles because it has been handled.
                        non_invertible_Z.remove(z)

                    break

                sample_degree = random.sample(possible_degrees, 1)[0]
                while len(non_invertible_Z) - sample_degree < 2:
                    sample_degree = random.sample(possible_degrees, 1)[0]

                # pick an assignment from remaining_assignments
                assignment = random.sample(remaining_assignments, 1)[0]
                # remove the assignment from remaining_assignments
                remaining_assignments.remove(assignment)

                similar_z_list = random.sample(non_invertible_Z, sample_degree)
                for z in similar_z_list:
                        mapping.append((z[0], assignment))

                        # remove the z from the list of non_invertibles because it has been handled.
                        non_invertible_Z.remove(z)


            # creating the mapping for the remaining discrete latents that are invertible

            # randomly choose len(invertible_Z) of remaining_assignments to assign them to invertible_Z
            assignments = random.sample(remaining_assignments, len(invertible_Z))

            # return the created mapping
            for i, z in enumerate(invertible_Z):
                mapping.append((z[0], assignments[i]))

            mapping = sorted(mapping, key=lambda x:x[0])
            Z = list(enumerate(Z_product))
    
    
        return mapping, Z
    